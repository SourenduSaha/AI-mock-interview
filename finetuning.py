# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IRMdmZaHV-gVu2x5f3TPzq4HXjLItHRE
"""

import os
os.environ["OPENAI_API_KEY"] = "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"

!pip install PyPDF2
!pip install python-docx
!pip install pandas
!pip install openai
!pip install pydub
!pip install google-cloud-speech
!pip install google-cloud-storage
!pip install python-dotenv
!pip install langchain
!pip install langchain_community
!pip install langchain_openai
!pip install chromadb

import time
import os
import re
import json
import io
import numpy as np
import urllib.parse
from difflib import SequenceMatcher

# File handling and parsing libraries
from PyPDF2 import PdfReader
import docx
import pandas as pd
from dotenv import load_dotenv

# OpenAI integration
from openai import OpenAI

# Audio processing
from pydub import AudioSegment
from google.cloud import speech_v1p1beta1 as speech
from google.cloud import storage

# RAG components
from langchain_core.prompts import PromptTemplate
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader
from langchain.chains import RetrievalQA

#----------------------------------------
# UTILITY FUNCTIONS
#----------------------------------------

def read_file(file_path):
    """Generic function to read file content based on extension"""
    try:
        # Determine file type based on extension
        file_extension = os.path.splitext(file_path)[1].lower()

        # Read the file content based on type
        if file_extension == '.pdf':
            return read_pdf(file_path)
        elif file_extension == '.docx':
            return read_docx(file_path)
        elif file_extension == '.txt':
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        elif file_extension in ['.csv', '.xlsx', '.xls']:
            # For tabular formats, convert to text representation
            return read_tabular(file_path)
        else:
            # Try to read as text for unknown file types
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
    except Exception as e:
        print(f"Error reading file {file_path}: {str(e)}")
        return f"Could not read file {file_path}"

def read_pdf(pdf_path):
    """Extract text from PDF file"""
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        print(f"Error reading PDF: {str(e)}")
        return ""

def read_docx(docx_path):
    """Extract text from DOCX file"""
    try:
        doc = docx.Document(docx_path)
        text = []
        for paragraph in doc.paragraphs:
            text.append(paragraph.text)
        return "\n".join(text)
    except Exception as e:
        print(f"Error reading DOCX: {str(e)}")
        return ""

def read_tabular(file_path):
    """Extract text representation from tabular files (CSV, Excel)"""
    try:
        extension = os.path.splitext(file_path)[1].lower()
        if extension == '.csv':
            df = pd.read_csv(file_path)
        else:  # Excel formats
            df = pd.read_excel(file_path)

        # Convert DataFrame to text representation
        text = "Resume in tabular format:\n\n"
        for col in df.columns:
            text += f"{col}:\n"
            for val in df[col].dropna():
                text += f"- {val}\n"
            text += "\n"

        return text
    except Exception as e:
        print(f"Error reading tabular file: {str(e)}")
        return ""

def convert_https_to_gcs_uri(https_url):
    """Convert HTTPS URL to Google Cloud Storage URI"""
    try:
        # Parse the URL
        parsed_url = urllib.parse.urlparse(https_url)
        # Extract bucket name and object name
        path_parts = parsed_url.path.lstrip('/').split('/', 1)
        if len(path_parts) == 2:
            bucket_name, object_name = path_parts
            # Decode URL-encoded characters in the object name
            object_name = urllib.parse.unquote(object_name)
            return f"gs://{bucket_name}/{object_name}"
        else:
            raise ValueError(f"Invalid HTTPS URL format: {https_url}")
    except Exception as e:
        print(f"Error converting URL to GCS URI: {str(e)}")
        return None

#----------------------------------------
# RESUME AND JOB DESCRIPTION ANALYSIS
#----------------------------------------

def parse_resume_with_ai(resume_text):
    """Use AI to extract structured information from resume text"""
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        Extract structured information from the following resume:

        {resume_text}

        Return the information in this JSON format:
        {{
            "contact_info": {{
                "name": "",
                "email": "",
                "phone": "",
                "location": ""
            }},
            "summary": "",
            "education": [
                {{
                    "degree": "",
                    "institution": "",
                    "dates": "",
                    "gpa": "",
                    "details": []
                }}
            ],
            "experience": [
                {{
                    "title": "",
                    "company": "",
                    "dates": "",
                    "location": "",
                    "responsibilities": []
                }}
            ],
            "skills": {{
                "technical": [],
                "soft": [],
                "languages": [],
                "tools": []
            }},
            "projects": [
                {{
                    "name": "",
                    "description": "",
                    "technologies": [],
                    "outcomes": []
                }}
            ],
            "certifications": [],
            "years_of_experience": 0,
            "domain_expertise": []
        }}

        If a field can't be determined from the resume, use null or an empty array as appropriate.
        For "years_of_experience", determine the total years of professional experience based on work history.
        For "domain_expertise", identify industry domains where the candidate has experience.
        """

        messages = [
            {"role": "system", "content": "You are an expert resume parser. Extract structured information from resumes accurately."},
            {"role": "user", "content": prompt}
        ]

        start = time.time()
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            response_format={"type": "json_object"}
        )
        end = time.time()

        structured_resume = json.loads(response.choices[0].message.content)
        print(f"Resume parsed in {round(end - start, 2)} seconds")

        return structured_resume

    except Exception as e:
        print(f"Error parsing resume with AI: {str(e)}")
        return {
            "contact_info": {},
            "education": [],
            "experience": [],
            "skills": {},
            "years_of_experience": 0,
            "domain_expertise": []
        }

def extract_resume_structure(resume_path):
    """Extract structured information from a resume file"""
    try:
        # Read the file content
        resume_text = read_file(resume_path)

        # Use OpenAI to extract structured information
        structured_resume = parse_resume_with_ai(resume_text)
        return structured_resume

    except Exception as e:
        print(f"Error extracting resume structure: {str(e)}")
        # Return a minimal structure if parsing fails
        return {
            "contact_info": {},
            "education": [],
            "experience": [],
            "skills": [],
            "full_text": "Could not parse resume"
        }

def extract_job_description_structure(jd_text):
    """Extract structured information from job description text"""
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        Extract structured information from the following job description:

        {jd_text}

        Return the information in this JSON format:
        {{
            "title": "",
            "company": "",
            "location": "",
            "employment_type": "",
            "summary": "",
            "responsibilities": [],
            "requirements": {{
                "required_skills": [],
                "preferred_skills": [],
                "education": [],
                "experience": []
            }},
            "benefits": [],
            "industry": "",
            "seniority_level": "",
            "key_technologies": []
        }}

        If a field can't be determined from the job description, use null or an empty array as appropriate.
        For "industry", identify the industry sector this role belongs to.
        For "seniority_level", determine if this is entry-level, mid-level, senior, or executive.
        For "key_technologies", identify specific technologies, tools, or platforms mentioned as requirements.
        """

        messages = [
            {"role": "system", "content": "You are an expert job description parser. Extract structured information from job descriptions accurately."},
            {"role": "user", "content": prompt}
        ]

        start = time.time()
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            response_format={"type": "json_object"}
        )
        end = time.time()

        structured_jd = json.loads(response.choices[0].message.content)
        print(f"Job description parsed in {round(end - start, 2)} seconds")

        return structured_jd

    except Exception as e:
        print(f"Error parsing job description with AI: {str(e)}")
        return {
            "title": "",
            "company": "",
            "responsibilities": [],
            "requirements": {"required_skills": []},
            "industry": "",
            "seniority_level": ""
        }

def analyze_resume_job_alignment(structured_resume, structured_jd):
    """Analyze the alignment between resume and job description"""
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        # Prepare the input for analysis
        resume_json = json.dumps(structured_resume, indent=2)
        jd_json = json.dumps(structured_jd, indent=2)

        prompt = f"""
        Analyze the alignment between this candidate's resume and the job description:

        RESUME:
        {resume_json}

        JOB DESCRIPTION:
        {jd_json}

        Provide a JSON analysis with the following structure:
        {{
            "overall_match_score": 0-100,
            "skill_match": {{
                "score": 0-100,
                "matching_skills": [],
                "missing_skills": []
            }},
            "experience_match": {{
                "score": 0-100,
                "relevant_experience": [],
                "experience_gaps": []
            }},
            "education_match": {{
                "score": 0-100,
                "comments": ""
            }},
            "strengths": [],
            "areas_of_concern": [],
            "suggested_interview_focus_areas": []
        }}

        Base your analysis on how well the candidate's qualifications align with the job requirements.
        """

        messages = [
            {"role": "system", "content": "You are an expert resume analyzer with deep knowledge of job requirements and candidate evaluation."},
            {"role": "user", "content": prompt}
        ]

        start = time.time()
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            response_format={"type": "json_object"}
        )
        end = time.time()

        alignment_analysis = json.loads(response.choices[0].message.content)
        print(f"Resume-job alignment analyzed in {round(end - start, 2)} seconds")

        return alignment_analysis

    except Exception as e:
        print(f"Error analyzing resume-job alignment: {str(e)}")
        return {
            "overall_match_score": 50,
            "strengths": ["Could not perform detailed analysis"],
            "areas_of_concern": ["Could not perform detailed analysis"],
            "suggested_interview_focus_areas": ["Technical skills", "Experience", "Problem-solving"]
        }

#----------------------------------------
# AUDIO PROCESSING FUNCTIONS
#----------------------------------------

def upload_to_gcp_storage(file_data, bucket_name):
    """Upload file to Google Cloud Storage"""
    try:
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        timestamp = int(time.time())
        blob_name = f"recording_{timestamp}.webm"
        blob = bucket.blob(blob_name)

        # Upload the file
        blob.upload_from_string(file_data.read(), content_type="audio/webm")

        # Generate a publicly accessible URL
        return f"https://storage.googleapis.com/{bucket_name}/{blob_name}"
    except Exception as e:
        print(f"Error uploading to GCP: {str(e)}")
        return None

def speech_to_text(gcs_uri):
    """Convert speech to text using Google Speech-to-Text API"""
    try:
        client = speech.SpeechClient()

        # Configure the recognition request
        audio = speech.RecognitionAudio(uri=gcs_uri)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            sample_rate_hertz=48000,
            language_code='en-US',
            enable_automatic_punctuation=True,
            audio_channel_count=1,
            enable_word_time_offsets=True
        )

        # Use long_running_recognize for files longer than 1 minute
        operation = client.long_running_recognize(config=config, audio=audio)
        print("Waiting for speech-to-text operation to complete...")
        response = operation.result(timeout=90)

        # Process the response
        transcript = ""
        for result in response.results:
            transcript += result.alternatives[0].transcript + " "

        return transcript.strip()
    except Exception as e:
        print(f"Error in speech-to-text: {str(e)}")
        return ""

def extract_audio_features(gcs_uri):
    """Extract audio features from a WebM file"""
    try:
        # Load audio from GCS
        bucket_name = gcs_uri.split('/')[2]
        blob_name = '/'.join(gcs_uri.split('/')[3:])
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        audio_bytes = io.BytesIO()
        blob.download_to_file(audio_bytes)
        audio_bytes.seek(0)

        # Load the audio using pydub
        webm_audio = AudioSegment.from_file(audio_bytes, format="webm")

        # Convert to numpy array for processing
        samples = np.array(webm_audio.get_array_of_samples()).astype(np.float64)
        if webm_audio.channels == 2:
            samples = samples.reshape((-1, 2)).mean(axis=1)

        # Extract basic audio features (simplified version)
        audio_duration = webm_audio.duration_seconds
        sample_rate = webm_audio.frame_rate

        # Calculate audio intensity (volume)
        avg_volume = np.mean(np.abs(samples))

        # Calculate pauses (periods of relative silence)
        silence_threshold = avg_volume * 0.1
        is_silence = np.abs(samples) < silence_threshold
        silence_ranges = []
        in_silence = False
        silence_start = 0

        for i, silent in enumerate(is_silence):
            if silent and not in_silence:
                in_silence = True
                silence_start = i
            elif not silent and in_silence:
                in_silence = False
                silence_duration = (i - silence_start) / sample_rate
                if silence_duration >= 0.5:  # Only count pauses >= 0.5 seconds
                    silence_ranges.append(silence_duration)

        # Calculate features
        features = {
            'audio_length': float(audio_duration),
            'avg_volume': float(avg_volume),
            'max_pause': float(max(silence_ranges)) if silence_ranges else 0.0,
            'avg_pause': float(np.mean(silence_ranges)) if silence_ranges else 0.0,
            'num_pauses': len(silence_ranges)
        }

        return features
    except Exception as e:
        print(f"Error extracting audio features: {str(e)}")
        return {
            'audio_length': 0.0,
            'avg_volume': 0.0,
            'max_pause': 0.0,
            'avg_pause': 0.0,
            'num_pauses': 0
        }

def process_audio_recording(webm_file):
    """Process audio recording and extract transcript"""
    try:
        print("Processing WebM file")

        # Save WebM file to GCP storage
        webm_url = upload_to_gcp_storage(webm_file, "lia_recordings")

        # Convert HTTPS URL to GCS URI
        gcs_uri = convert_https_to_gcs_uri(webm_url)
        print(f"GCS URI: {gcs_uri}")

        # Get transcript using Google Speech-to-Text
        transcript = speech_to_text(gcs_uri)

        # Extract audio features
        audio_features = extract_audio_features(gcs_uri)

        return {
            'transcript': transcript,
            'audio_url': webm_url,
            'audio_features': audio_features
        }
    except Exception as e:
        print(f"Error processing audio recording: {str(e)}")
        return None

#----------------------------------------
# TEXT FEATURE EXTRACTION
#----------------------------------------

class TextFeatureExtractor:
    def __init__(self):
        # Filler words list
        self.filler_words = [
            "um", "uhm", "uh", "uhh", "er", "err", "ah", "ahh", "like", "you know",
            "sort of", "kind of", "kinda", "sorta", "basically", "literally", "actually",
            "so", "well", "I mean", "you see", "right", "okay", "ok", "yeah", "yea",
            "you know what I mean", "I guess", "just", "stuff", "things", "whatever"
        ]

        # Quantifier words list
        self.quantifiers = [
            "all", "another", "any", "both", "each", "either", "enough", "every",
            "few", "fewer", "little", "less", "many", "more", "much", "neither",
            "no", "several", "some", "a few", "a little", "a lot of", "lots of",
            "most", "plenty", "numerous", "countless"
        ]

        # Compile regex patterns
        self.filler_pattern = r'\b(' + '|'.join(map(re.escape, self.filler_words)) + r')\b'
        self.quantifier_pattern = r'\b(' + '|'.join(map(re.escape, self.quantifiers)) + r')\b'

    def extract_features(self, text, audio_length):
        """Extract text features from the given text"""
        try:
            # Convert text to lowercase for consistent matching
            text = text.lower()

            # Count total words (splitting on whitespace)
            total_words = len(text.split())

            # Count unique words
            unique_words = len(set(text.split()))

            # Count filler words
            filler_count = len(re.findall(self.filler_pattern, text))

            # Count quantifier words
            quantifier_count = len(re.findall(self.quantifier_pattern, text))

            # Calculate percentages (avoid division by zero)
            filler_pct = (filler_count / total_words * 100) if total_words > 0 else 0
            quantifier_pct = (quantifier_count / total_words * 100) if total_words > 0 else 0

            # Calculate words per second and unique words per second
            wpsec = (total_words / audio_length) if audio_length > 0 else 0
            upsec = (unique_words / audio_length) if audio_length > 0 else 0

            return {
                'quantifier_words_pct': float(quantifier_pct),
                'filler_nonfluency_pct': float(filler_pct),
                'word_count': total_words,
                'wpsec': float(wpsec),
                'upsec': float(upsec)
            }

        except Exception as e:
            print(f"Error extracting text features: {str(e)}")
            return {
                'quantifier_words_pct': 0.0,
                'filler_nonfluency_pct': 0.0,
                'word_count': 0,
                'wpsec': 0.0,
                'upsec': 0.0
            }

#----------------------------------------
# RAG (RETRIEVAL AUGMENTED GENERATION)
#----------------------------------------

def initialize_rag(file_path):
    """Initialize Retrieval-Augmented Generation"""
    try:
        print("Initializing RAG with knowledge base...")
        loader = TextLoader(file_path)
        documents = loader.load()

        # Initialize OpenAI embeddings
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        embeddings = OpenAIEmbeddings(api_key=api_key)

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = text_splitter.split_documents(documents)

        vector_db = Chroma.from_documents(docs, embeddings)

        return vector_db
    except Exception as e:
        print(f"Error initializing RAG: {str(e)}")
        return None

def setup_retrieval_qa(vector_db):
    """Set up the retrieval QA system"""
    try:
        if not vector_db:
            return None

        retriever = vector_db.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4}
        )

        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")

        llm = ChatOpenAI(
            model_name="gpt-4o",
            api_key=api_key,
            temperature=0.1,
            max_tokens=2000
        )

        qa = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True
        )

        return qa
    except Exception as e:
        print(f"Error setting up retrieval QA: {str(e)}")
        return None

#----------------------------------------
# QUESTION GENERATION
#----------------------------------------

def generate_initial_question(structured_resume, structured_jd):
    """Generate the initial interview question based on structured resume and job description"""
    # Prepare resume and job description in a structured format
    resume_summary = {
        "name": structured_resume.get("contact_info", {}).get("name", ""),
        "experience": [
            {
                "title": exp.get("title", ""),
                "company": exp.get("company", ""),
                "responsibilities": exp.get("responsibilities", [])[:3]  # Limit to 3 responsibilities
            } for exp in structured_resume.get("experience", [])[:3]  # Limit to 3 most recent experiences
        ],
        "education": [
            {
                "degree": edu.get("degree", ""),
                "institution": edu.get("institution", "")
            } for edu in structured_resume.get("education", [])
        ],
        "skills": structured_resume.get("skills", {}),
        "projects": [proj.get("name", "") for proj in structured_resume.get("projects", [])[:3]]
    }

    jd_summary = {
        "title": structured_jd.get("title", ""),
        "company": structured_jd.get("company", ""),
        "responsibilities": structured_jd.get("responsibilities", [])[:5],  # Limit to 5 key responsibilities
        "required_skills": structured_jd.get("requirements", {}).get("required_skills", []),
        "industry": structured_jd.get("industry", "")
    }

    # Convert to JSON strings
    resume_json = json.dumps(resume_summary, indent=2)
    jd_json = json.dumps(jd_summary, indent=2)

    # Prepare messages
    messages = [
        {"role": "system", "content": "You are an expert AI interviewer for data science roles."},
        {"role": "user", "content": f"""
Given the structured resume and job description below, generate 1 thoughtful and role-specific technical interview question.

STRUCTURED RESUME:
{resume_json}

STRUCTURED JOB DESCRIPTION:
{jd_json}

Guidelines for your question:
1. Be specific to the candidate's background and the job requirements
2. Focus on technical knowledge and practical application
3. Target skills or experiences that appear most relevant for this role
4. Keep the question under 30 words and end with a question mark
5. Make it conversational but substantive
"""}
    ]

    # Call OpenAI API
    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    start = time.time()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    end = time.time()

    initial_question = response.choices[0].message.content
    print(f"\nInitial Question:\n{initial_question}")
    print(f"Took {round(end - start, 2)} seconds\n")

    return initial_question, messages

def generate_follow_up_questions(messages):
    """Generate follow-up questions based on the initial question"""
    messages.append({"role": "user", "content": f"""
Based on the initial interview question generated above, generate 3 additional follow-up questions that are related to those questions.
Each question should:
1. Be clearly distinct from the others
2. Probe different aspects of the candidate's knowledge and experience
3. Follow a logical progression of complexity
4. Be specific to the data science role indicated in the context
5. Be formatted as numbered questions (1., 2., 3.)
"""})

    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    start = time.time()
    followup_response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )
    end = time.time()

    follow_up_questions = followup_response.choices[0].message.content
    print(f"Generated follow-up questions:\n{follow_up_questions}")
    print(f"Took {round(end - start, 2)} seconds\n")

    # Extract the questions from the response
    questions = []
    for line in follow_up_questions.strip().split('\n'):
        if re.match(r'^\d+\.', line.strip()):
            questions.append(line.strip())

    return questions

def generate_tailored_questions(personal_profile):
    """Generate interview questions tailored to the candidate's background and role"""
    try:
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        prompt = f"""
        Generate 5 tailored technical interview questions for a {personal_profile['role']} position based on the candidate's background:

        Candidate Profile:
        - Experience: {personal_profile['experience']} years
        - Education: {', '.join(personal_profile['education'])}
        - Technical Skills: {', '.join(personal_profile['skills']['technical'][:10])}
        - Domain Expertise: {', '.join(personal_profile['domain_expertise'])}

        Job Requirements:
        - Role: {personal_profile['role']} at {personal_profile['company']}
        - Industry: {personal_profile['industry']}
        - Seniority: {personal_profile['seniority_level']}
        - Key Technologies: {', '.join(personal_profile['key_technologies'])}
        - Key Responsibilities: {', '.join(personal_profile['job_responsibilities'][:3])}

        Generate 5 different types of questions:
        1. A technical knowledge question about a key technology required for the role
        2. A problem-solving question related to the industry challenges
        3. A scenario-based question about handling a specific job responsibility
        4. A question about a project mentioned in their background related to the job requirements
        5. A question that tests the candidate's understanding of how their skills apply to the company's industry

        Each question should:
        - Be specific to this candidate and role (not generic)
        - Be 1-2 sentences long
        - Probe for both knowledge and applied experience
        - Not require external resources to answer
        - End with a question mark

        Format each question as:
        "1. [Technical Knowledge] Question text"
        "2. [Problem Solving] Question text"
        etc.
        """

        messages = [
            {"role": "system", "content": "You are an expert technical interviewer for data science roles, with deep knowledge of industry best practices and technical requirements."},
            {"role": "user", "content": prompt}
        ]

        start = time.time()
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        end = time.time()

        questions = response.choices[0].message.content.strip().split("\n")
        print(f"Generated {len(questions)} tailored questions in {round(end - start, 2)} seconds")

        # Filter out any non-question lines and clean up formatting
        filtered_questions = []
        for question in questions:
            # Check if line starts with a number and contains a question mark
            if re.match(r'^\d+\.', question) and '?' in question:
                # Extract the question text, removing the category label if present
                question_text = re.sub(r'^\d+\.\s+\[[^\]]+\]\s+', '', question)
                filtered_questions.append(question_text)

        return filtered_questions

    except Exception as e:
        print(f"Error generating tailored questions: {str(e)}")
        return [
            "Tell me about your experience with data science projects.",
            "How would you approach a classification problem?",
            "What programming languages are you most comfortable with?",
            "Describe a challenging data problem you've solved.",
            "How do you stay updated with the latest developments in data science?"
        ]

def generate_dynamic_question(messages, user_response, retrieval_qa=None, personal_profile=None):
    """Generate a dynamic follow-up question based on the user's response"""
    # Add the user's response to the conversation
    messages.append({"role": "user", "content": user_response})

    # Try to use RAG-enhanced question generation if available
    if retrieval_qa and personal_profile:
        try:
            # Create a context prompt that includes the conversation history
            context_prompt = f"""
            Based on this interview conversation so far and the candidate's profile:

            Profile: {personal_profile}

            Last Response: {user_response}

            Generate a follow-up interview question that:
            1. Builds directly on the candidate's previous answer
            2. Is under 35 words
            3. Is phrased directly as a question
            4. Probes deeper into technical knowledge or experience
            """

            # Get the response with source documents
            context_response = retrieval_qa.retriever.vectorstore.similarity_search_with_relevance_scores(context_prompt)

            # Check if we have good matches
            use_rag = False
            if len(context_response) > 1:
                avg_similarity = sum(score for _, score in context_response) / len(context_response)
                use_rag = avg_similarity >= 0.65
                print(f"Found {len(context_response)} chunks with average similarity score: {avg_similarity}")

            if use_rag:
                print("Using RAG knowledge base for question generation")
                response = retrieval_qa({"query": context_prompt})
                follow_up_question = response['result'].strip()
                return follow_up_question

        except Exception as e:
            print(f"Error using RAG for question generation: {str(e)}")

    # Fall back to OpenAI if RAG fails or is not available
    print("Using OpenAI for question generation")

    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # Create a new system message
    system_message = {
        "role": "system",
        "content": """
            You are an expert technical interviewer for data science roles.
            Generate a thoughtful follow-up question based on the candidate's response.
            The question should:
            1. Dig deeper into a specific aspect mentioned by the candidate
            2. Be conversational but technically substantive
            3. Be no longer than 30 words
            4. End with a question mark
        """
    }

    # Create a new messages array with the system message first
    formatted_messages = [system_message] + messages

    start = time.time()
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=formatted_messages,
        temperature=0.2
    )
    end = time.time()

    follow_up_question = response.choices[0].message.content
    print(f"\nDynamic Follow-Up Question: {follow_up_question}")
    print(f"Took {round(end - start, 2)} seconds\n")

    return follow_up_question

#----------------------------------------
# ANSWER EVALUATION
#----------------------------------------

def generate_expert_answer(question, retrieval_qa=None, personal_profile=None):
    """Generate an expert answer to the interview question"""
    if not retrieval_qa or not personal_profile:
        return "Expert answers require a retrieval QA system and personal profile."

    template = f"""
    You are an experienced data scientist in a job interview. Answer the following question naturally as if speaking to the interviewer, using your provided personal profile for context.

    Context:
    Personal Profile: {personal_profile}
    Question: {question}

    Guidelines for your response:
    - Speak in first person ("I", "my", "we")
    - Use natural transitions and connecting phrases
    - Keep it concise (150-200 words)
    - Include a brief opening statement that directly answers the question
    - Follow with a technical explanation using correct terminology
    - Share a specific example from your personal profile
    - Conclude with the business impact or practical application

    Response style:
    - Conversational and engaging, as if speaking in person
    - Professional but approachable
    - Show both technical expertise and communication skills
    - Avoid formal documentation style or academic tone
    - No bullet points or formatting - use natural speech flow

    Example flow:
    "In my experience... [direct answer]. This works because... [technical explanation]. For instance, when I was at... [personal example]. This approach helped us... [business impact]"

    Remember: You're having a conversation, not writing a report. Make it engaging while showcasing your expertise.
    """

    try:
        # First, try to get relevant chunks and check similarity
        context_response = retrieval_qa.retriever.vectorstore.similarity_search_with_relevance_scores(template)

        # Set similarity score threshold
        SIMILARITY_THRESHOLD = 0.65

        # Calculate average similarity if we have chunks
        use_rag = False
        if len(context_response) > 1:
            avg_similarity = sum(score for _, score in context_response) / len(context_response)
            use_rag = avg_similarity >= SIMILARITY_THRESHOLD
            print(f"Found {len(context_response)} chunks with average similarity score: {avg_similarity}")

        if use_rag:
            print("Generating expert answer using RAG knowledge base")
            answer = retrieval_qa({"query": template})
            return answer['result']

        # If similarity is too low, use OpenAI directly
        print("Generating expert answer using GPT-4o")
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        messages = [
            {"role": "system", "content": "You are an experienced data scientist in a job interview."},
            {"role": "user", "content": template}
        ]

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.1,
            max_tokens=2000
        )

        return response.choices[0].message.content

    except Exception as e:
        print(f"Error generating expert answer: {str(e)}")
        return "Could not generate expert answer due to an error."

def evaluate_answer(user_answer, expert_answer, question, audio_features=None, text_features=None):
    """Evaluate the user's answer compared to the expert answer"""

    evaluation_prompt = f"""
    You are an expert interviewer and evaluator for data science roles. Compare the candidate's answer to an expert reference answer for the same question.

    Question: {question}

    Candidate's Answer: {user_answer}

    Expert Reference Answer: {expert_answer}

    Audio Features: {audio_features if audio_features else 'Not available'}

    Text Features: {text_features if text_features else 'Not available'}

    Evaluate the candidate's answer on the following criteria:
    1. Technical Accuracy (0-10): How well does the answer demonstrate understanding of technical concepts?
    2. Relevance (0-10): How directly does the answer address the question asked?
    3. Depth (0-10): How well does the answer explore the topic beyond surface level?
    4. Communication (0-10): How clear, concise, and well-structured is the answer?
    5. Practical Application (0-10): How well does the answer connect to real-world applications?

    For each criterion, provide:
    - A numerical score
    - 1-2 sentences of specific feedback
    - A specific improvement suggestion

    Then provide an Overall Score (0-100) and 2-3 sentences of summary feedback.
    """

    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    messages = [
        {"role": "system", "content": "You are an expert AI interviewer and evaluator for data science roles."},
        {"role": "user", "content": evaluation_prompt}
    ]

    try:
        start = time.time()
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        end = time.time()

        evaluation = response.choices[0].message.content
        print(f"\nAnswer Evaluation:\n{evaluation}")
        print(f"Took {round(end - start, 2)} seconds\n")

        return evaluation
    except Exception as e:
        print(f"Error evaluating answer: {str(e)}")
        return "Could not evaluate the answer due to an error."

#----------------------------------------
# INTERVIEW SESSION CLASS
#----------------------------------------

class InterviewSession:
    def __init__(self, resume_path, job_description_path):
        # Parse resume and job description
        self.resume_text = read_file(resume_path)
        self.job_description_text = read_file(job_description_path)

        # Extract structured information
        self.structured_resume = extract_resume_structure(resume_path)
        self.structured_jd = extract_job_description_structure(self.job_description_text)

        # Create personal profile from structured information
        self.personal_profile = self.create_personal_profile()

        # Initialize interview state
        self.interview_dict = {}
        self.question_num = 0
        self.messages = []
        self.current_question = None
        self.follow_up_questions = []
        self.audio_features = []
        self.text_features = []

        # Initialize RAG if available
        try:
            self.vector_db = initialize_rag("data_science.txt")  # Use a local file path instead of GCS
            self.retrieval_qa = setup_retrieval_qa(self.vector_db)
        except Exception as e:
            print(f"Warning: RAG initialization failed: {str(e)}")
            self.vector_db = None
            self.retrieval_qa = None

    def create_personal_profile(self):
        """Create a personal profile from structured resume and job description"""
        profile = {
            'name': self.structured_resume.get('contact_info', {}).get('name', 'Candidate'),
            'resume': self.resume_text,
            'job_description': self.job_description_text,
            'role': self.structured_jd.get('title', 'Data Scientist'),
            'company': self.structured_jd.get('company', 'Company'),
            'industry': self.structured_jd.get('industry', 'Technology'),
            'experience': self.structured_resume.get('years_of_experience', '3-5'),
            'education': [edu.get('degree', '') + ' from ' + edu.get('institution', '')
                         for edu in self.structured_resume.get('education', [])],
            'skills': {
                'technical': self.structured_resume.get('skills', {}).get('technical', []),
                'soft': self.structured_resume.get('skills', {}).get('soft', [])
            },
            'domain_expertise': self.structured_resume.get('domain_expertise', []),
            'job_requirements': self.structured_jd.get('requirements', {}).get('required_skills', []),
            'job_responsibilities': self.structured_jd.get('responsibilities', []),
            'key_technologies': self.structured_jd.get('key_technologies', []),
            'seniority_level': self.structured_jd.get('seniority_level', 'Mid-level')
        }

        # Create a skill match score
        required_skills = set([skill.lower() for skill in profile['job_requirements']])
        candidate_skills = set([skill.lower() for skill in profile['skills']['technical']])

        if required_skills:
            profile['skill_match_score'] = len(required_skills.intersection(candidate_skills)) / len(required_skills)
        else:
            profile['skill_match_score'] = 0

        return profile

    def start_interview(self):
        """Start the interview with the initial question"""
        initial_question, self.messages = generate_initial_question(self.structured_resume, self.structured_jd)
        self.current_question = initial_question
        self.add_question(initial_question, 0)

        # Generate follow-up questions
        self.follow_up_questions = generate_follow_up_questions(self.messages.copy())

        return initial_question

    def add_question(self, question, question_num):
        """Add a question to the interview dictionary"""
        self.interview_dict[question_num] = {
            "question": question,
            "answer": None,
            "evaluation": None,
            "audio_features": None,
            "text_features": None
        }
        self.question_num = question_num

    def add_answer(self, answer, audio_data=None):
        """Add an answer to the current question"""
        question_num = self.question_num

        # Process audio if available
        audio_features = None
        text_features = None
        transcript = answer

        if audio_data:
            audio_result = process_audio_recording(audio_data)
            if audio_result:
                transcript = audio_result['transcript'] or answer
                audio_features = audio_result['audio_features']

                # Extract text features if we have audio length
                if audio_features and 'audio_length' in audio_features:
                    text_extractor = TextFeatureExtractor()
                    text_features = text_extractor.extract_features(transcript, audio_features['audio_length'])

        # Store the answer and features
        self.interview_dict[question_num]["answer"] = transcript
        self.interview_dict[question_num]["audio_features"] = audio_features
        self.interview_dict[question_num]["text_features"] = text_features

        # Generate expert answer for comparison
        expert_answer = generate_expert_answer(
            self.interview_dict[question_num]["question"],
            self.retrieval_qa,
            self.personal_profile
        )

        # Evaluate the answer
        evaluation = evaluate_answer(
            transcript,
            expert_answer,
            self.interview_dict[question_num]["question"],
            audio_features,
            text_features
        )

        self.interview_dict[question_num]["evaluation"] = evaluation
        self.interview_dict[question_num]["expert_answer"] = expert_answer

        return expert_answer, evaluation

    def next_question(self):
        """Generate the next question based on the previous answer"""
        if self.question_num == 0 and len(self.follow_up_questions) > 0:
            # Use the first pre-generated follow-up for the second question
            next_question = self.follow_up_questions[0]
            self.add_question(next_question, 1)
            return next_question

        # For subsequent questions, generate dynamically based on previous answers
        last_answer = self.interview_dict[self.question_num]["answer"]
        next_question = generate_dynamic_question(
            self.messages.copy(),
            last_answer,
            self.retrieval_qa,
            self.personal_profile
        )

        self.add_question(next_question, self.question_num + 1)
        return next_question

    def get_interview_summary(self):
        """Generate a summary of the interview with feedback"""
        load_dotenv()
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        summary_prompt = f"""
        You are an expert interviewer for data science roles. Analyze the complete interview below and provide a comprehensive summary with feedback.

        Interview for Data Science Role:

        {self.format_interview_transcript()}

        Please provide:
        1. Overall Assessment: Give a 2-3 paragraph summary of the candidate's performance
        2. Key Strengths: List 3-5 specific strengths demonstrated in the interview
        3. Areas for Improvement: List 2-3 specific areas where the candidate could improve
        4. Technical Competency: Rate the candidate's technical knowledge (1-10) with brief explanation
        5. Communication Skills: Rate the candidate's communication skills (1-10) with brief explanation
        6. Recommendation: Provide a clear hiring recommendation (Strongly Recommend, Recommend, Consider, or Do Not Recommend)
        """

        messages = [
            {"role": "system", "content": "You are an expert AI interviewer and evaluator for data science roles."},
            {"role": "user", "content": summary_prompt}
        ]

        try:
            start = time.time()
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages
            )
            end = time.time()

            interview_summary = response.choices[0].message.content
            print(f"\nInterview Summary:\n{interview_summary}")
            print(f"Took {round(end - start, 2)} seconds\n")

            return interview_summary
        except Exception as e:
            print(f"Error generating interview summary: {str(e)}")
            return "Could not generate interview summary due to an error."

    def format_interview_transcript(self):
        """Format the interview transcript for the summary"""
        transcript = ""
        for q_num in sorted(self.interview_dict.keys()):
            question = self.interview_dict[q_num]["question"]
            answer = self.interview_dict[q_num]["answer"]
            evaluation = self.interview_dict[q_num]["evaluation"]

            transcript += f"Q{q_num+1}: {question}\n\n"
            transcript += f"A{q_num+1}: {answer}\n\n"
            transcript += f"Evaluation: {evaluation}\n\n"
            transcript += "---\n\n"

        return transcript

#----------------------------------------
# MAIN EXECUTION
#----------------------------------------

def save_interview_results(interview, alignment_analysis):
    """Save interview results to file"""
    try:
        # Create a timestamped filename
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        filename = f"interview_results_{timestamp}.json"

        # Format results
        results = {
            "candidate_name": interview.personal_profile.get('name', 'Candidate'),
            "role": interview.personal_profile.get('role', 'Data Scientist'),
            "date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "resume_job_alignment": alignment_analysis,
            "interview_transcript": {},
            "overall_summary": interview.get_interview_summary()
        }

        # Add interview transcript
        for q_num in sorted(interview.interview_dict.keys()):
            results["interview_transcript"][f"q{q_num+1}"] = {
                "question": interview.interview_dict[q_num]["question"],
                "answer": interview.interview_dict[q_num]["answer"],
                "expert_answer": interview.interview_dict[q_num].get("expert_answer", ""),
                "evaluation": interview.interview_dict[q_num].get("evaluation", ""),
                "audio_features": interview.interview_dict[q_num].get("audio_features", {}),
                "text_features": interview.interview_dict[q_num].get("text_features", {})
            }

        # Save to file
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2)

        print(f"\nInterview results saved to {filename}")

    except Exception as e:
        print(f"Error saving interview results: {str(e)}")

def run_interview():
    """Main function to run the interview process"""
    # Set file paths
    resume_path = "resume.pdf"
    jd_path = "jd.txt"

    # Create interview session with enhanced resume and job description parsing
    interview = InterviewSession(resume_path, jd_path)

    # Analyze resume-job alignment
    alignment_analysis = analyze_resume_job_alignment(interview.structured_resume, interview.structured_jd)
    print("\n===== RESUME-JOB ALIGNMENT ANALYSIS =====")
    print(f"Overall Match Score: {alignment_analysis['overall_match_score']}/100")
    print("\nStrengths:")
    for strength in alignment_analysis['strengths'][:3]:
        print(f"- {strength}")
    print("\nAreas of Concern:")
    for concern in alignment_analysis['areas_of_concern'][:3]:
        print(f"- {concern}")
    print("\nSuggested Interview Focus Areas:")
    for area in alignment_analysis['suggested_interview_focus_areas'][:3]:
        print(f"- {area}")
    print("\n")

    # Generate tailored questions based on profile
    tailored_questions = generate_tailored_questions(interview.personal_profile)

    # Use tailored questions if available
    if tailored_questions and len(tailored_questions) >= 5:
        # Add technical knowledge question as the initial question
        interview.add_question(tailored_questions[0], 0)
        interview.current_question = tailored_questions[0]
        # Store the rest as follow-up questions
        interview.follow_up_questions = tailored_questions[1:]
    else:
        # Fall back to standard question generation
        initial_question = interview.start_interview()

    print("\n===== INTERVIEW STARTED =====\n")
    print(f"Interviewer: {interview.current_question}\n")

    while True:
        # Get user input (text or audio)
        user_input = input("Your Answer (or type 'exit' to end the interview): ")

        if user_input.lower() == "exit":
            break

        # Process user's answer (assumes text input only)
        expert_answer, evaluation = interview.add_answer(user_input)

        # Generate next question
        next_question = interview.next_question()

        print("\n----- Evaluation -----")
        print(evaluation)
        print("\n----- Expert Example Answer -----")
        print(expert_answer)
        print("\n----- Next Question -----")
        print(f"Interviewer: {next_question}\n")

    # Get interview summary
    print("\n===== INTERVIEW COMPLETED =====\n")
    summary = interview.get_interview_summary()
    print("\n===== INTERVIEW SUMMARY =====\n")
    print(summary)

    # Save interview transcript and feedback
    save_interview_results(interview, alignment_analysis)

    return interview

if __name__ == "__main__":
    interview_session = run_interview()